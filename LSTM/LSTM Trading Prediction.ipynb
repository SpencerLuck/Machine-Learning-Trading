{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "088912fc",
   "metadata": {},
   "source": [
    "# LSTM Trade Signal\n",
    "\n",
    "This notebook seeks to use LSTM neural networks to give a trading signal based on a variant of the triple barrier labelling method. We will consider our trade horizon to be 5 timesteps (hours) into the future, with take profit and stop loss values being set as a factor of the Average True Range away from the current price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a39bbca1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: legitindicators in c:\\programdata\\anaconda3\\lib\\site-packages (0.0.66)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from legitindicators) (1.20.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -m (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ym (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -m (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ym (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -m (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ym (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -m (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ym (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -m (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ym (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -m (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ym (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -m (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ym (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -m (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ym (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -m (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ym (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -m (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ym (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -m (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ym (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -m (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ym (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas_ta in c:\\programdata\\anaconda3\\lib\\site-packages (0.3.14b0)\n",
      "Requirement already satisfied: pandas in c:\\users\\spenc\\appdata\\roaming\\python\\python39\\site-packages (from pandas_ta) (1.4.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->pandas_ta) (1.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->pandas_ta) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->pandas_ta) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->pandas_ta) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Installing technical indicator library for the Average True Range\n",
    "!pip install pandas_ta\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "import pandas_ta as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e5deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 20\n",
    "\n",
    "PREDICT_HORIZON1 = 1\n",
    "PREDICT_HORIZON2 = 2\n",
    "PREDICT_HORIZON3 = 3\n",
    "PREDICT_HORIZON4 = 4\n",
    "PREDICT_HORIZON5 = 5\n",
    "\n",
    "\n",
    "# ATR factors\n",
    "TP_ATR = 1\n",
    "SL_ATR = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab75d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying for 5 candles in the future\n",
    "def classify(current_close, current_atr, future_high_1, future_low_1, future_high_2, future_low_2, \n",
    "                    future_high_3, future_low_3, future_high_4, future_low_4, future_high_5, future_low_5):\n",
    "    \n",
    "  \n",
    "    min_price = min(future_low_1, future_low_2, future_low_3, future_low_4, future_low_5)\n",
    "    max_price = max(future_high_1, future_high_2, future_high_3, future_high_4, future_high_5)\n",
    "\n",
    "\n",
    "    TP_BUY = current_close + TP_ATR*current_atr\n",
    "    SL_BUY = current_close - SL_ATR*current_atr\n",
    "    TP_SELL = current_close - TP_ATR*current_atr\n",
    "    SL_SELL = current_close + SL_ATR*current_atr\n",
    "\n",
    "    # Uptrend\n",
    "    if float(max_price) >= TP_BUY and float(min_price) > SL_BUY and float(min_diff) > 0:\n",
    "        return 2\n",
    "\n",
    "    # Downtrend\n",
    "    elif float(min_price) <= TP_SELL and float(max_price) < SL_SELL and float(max_diff) < 0:\n",
    "        return 0 \n",
    "\n",
    "    # Flat trend\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(df):\n",
    "\n",
    "    for col in df.columns: \n",
    "        col_end = col.rsplit('_', -1)[-1] # get the last word of the string\n",
    "        if col != 'target':\n",
    "            if col_end == 'volume':\n",
    "                df[col] = (df[col].values - df[col].mean())/df[col].std() # standardizing volume (mean 0 , std 1)\n",
    "\n",
    "            elif col_end == 'value':\n",
    "                df[col] = (df[col].values - df[col].mean())/df[col].std() # standardizing indicator values (mean 0 , std 1)\n",
    "\n",
    "            elif col_end == 'open' or col_end == 'high' or col_end == 'low' or col_end == 'close': \n",
    "                df[col] = (df[col].values - df[col].mean())/df[col].std() # standardizing price returns\n",
    "\n",
    "    df.dropna(inplace=True)  \n",
    "\n",
    "\n",
    "    sequential_data = []  \n",
    "    prev_days = deque(maxlen=SEQ_LEN)  \n",
    "\n",
    "    for i in df.values:  # iterate over the values\n",
    "        prev_days.append([n for n in i[:-1]])  # store each row excluding target\n",
    "        if len(prev_days) == SEQ_LEN:  # 20 sequences \n",
    "            sequential_data.append([np.array(prev_days), i[-1]])  \n",
    "\n",
    "    random.shuffle(sequential_data)  \n",
    "\n",
    "    buys = []  \n",
    "    sells = []  \n",
    "    flats = []\n",
    "\n",
    "    # ---------------------------------------------------------------------------\n",
    "    for seq, target in sequential_data:  \n",
    "        if target == 0:  # sell\n",
    "            sells.append([seq, target])  \n",
    "        if target == 1:  # flat\n",
    "            flats.append([seq, target])  \n",
    "        elif target == 2:  # buy\n",
    "            buys.append([seq, target])  \n",
    "\n",
    "    \n",
    "    random.shuffle(buys)  \n",
    "    random.shuffle(sells)  \n",
    "    random.shuffle(flats)  \n",
    "    \n",
    "    # Balancing our dataset\n",
    "    lower = min(len(buys), len(sells), len(flats))  \n",
    "\n",
    "    buys = buys[:lower]  \n",
    "    flats = flats[:lower]\n",
    "    sells = sells[:lower] \n",
    "\n",
    "    sequential_data = buys+flats+sells  \n",
    "    random.shuffle(sequential_data)  \n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for seq, target in sequential_data: \n",
    "        X.append(seq)  \n",
    "        y.append(target)  \n",
    "\n",
    "    return np.array(X), y  \n",
    "\n",
    "\n",
    "\n",
    "def preprocess_stats_df(main_df):\n",
    "    \n",
    "    df = main_df.copy()\n",
    "    stats_dict = {}\n",
    "                      \n",
    "    for col in df.columns:\n",
    "        col_end = col.rsplit('_', -1)[-1] # get the last word of the string\n",
    "        if col_end == 'volume':\n",
    "            mean = df[col].mean()\n",
    "            std = df[col].std()\n",
    "            stats_dict[f'{col}'] = {'mean': mean, 'std': std}\n",
    "\n",
    "        elif col_end == 'value':\n",
    "            mean = df[col].mean()\n",
    "            std = df[col].std()\n",
    "            stats_dict[f'{col}'] = {'mean': mean, 'std': std}\n",
    "\n",
    "        elif col_end == 'open' or col_end == 'high' or col_end == 'low' or col_end == 'close':\n",
    "            mean = df[col].mean()\n",
    "            std = df[col].std()\n",
    "            stats_dict[f'{col}'] = {'mean': mean, 'std': std}\n",
    "\n",
    "    return stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1d1eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crypto hourly data\n",
    "path = ''\n",
    "main_df = pd.read_csv(path)\n",
    "main_df.set_index('time', inplace=True)\n",
    "\n",
    "main_df.sort_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee5a794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time transformations\n",
    "\n",
    "day = 60*60*24 # seconds in the day\n",
    "week = 60*60*24*7 # seconds in week\n",
    "\n",
    "main_df['Day_sin'] = np.sin(main_df.index * (2 * np.pi / day))\n",
    "main_df['Day_cos'] = np.cos(main_df.index * (2 * np.pi / day))\n",
    "main_df['Week_sin'] = np.sin(main_df.index * (2 * np.pi / week))\n",
    "main_df['Week_cos'] = np.cos(main_df.index * (2 * np.pi / week))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34407a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "\n",
    "main_df['atr_value'] = ta.atr(high=main_df['high'], low=main_df['low'], \n",
    "                              close=main_df['close'])\n",
    "\n",
    "\n",
    "for i in [1, 2, 3, 5, 10, 20]:    \n",
    "    main_df[f'ret_{i}_close'] = main_df['close'].pct_change(i)\n",
    "    main_df[f'ret_{i}_high'] = main_df['high'].pct_change(i)\n",
    "    main_df[f'ret_{i}_low'] = main_df['low'].pct_change(i)\n",
    "    main_df[f'ret_{i}_open'] = main_df['open'].pct_change(i)\n",
    "    main_df[f'ret_{i}_volume'] = main_df['volume'].pct_change(i)\n",
    "    \n",
    "\n",
    "main_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "main_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51774845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats dictionary for deployment (best practice to keep commented when not needing it)\n",
    "# stats = preprocess_stats_df(main_df)\n",
    "# stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3ccc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating columns for future high and low prices by shifting values from future\n",
    "main_df['future_high_1'] = main_df['high'].shift(-PREDICT_HORIZON1)\n",
    "main_df['future_low_1'] = main_df['low'].shift(-PREDICT_HORIZON1)\n",
    "\n",
    "main_df['future_high_2'] = main_df['high'].shift(-PREDICT_HORIZON2)\n",
    "main_df['future_low_2'] = main_df['low'].shift(-PREDICT_HORIZON2)\n",
    "\n",
    "main_df['future_high_3'] = main_df['high'].shift(-PREDICT_HORIZON3)\n",
    "main_df['future_low_3'] = main_df['low'].shift(-PREDICT_HORIZON3)\n",
    "\n",
    "main_df['future_high_4'] = main_df['high'].shift(-PREDICT_HORIZON4)\n",
    "main_df['future_low_4'] = main_df['low'].shift(-PREDICT_HORIZON4)\n",
    "\n",
    "main_df['future_high_5'] = main_df['high'].shift(-PREDICT_HORIZON5)\n",
    "main_df['future_low_5'] = main_df['low'].shift(-PREDICT_HORIZON5)\n",
    "\n",
    "main_df.dropna(inplace=True)\n",
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ef725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target column (y value)\n",
    "main_df['target'] = list(map(classify, main_df['close'], main_df['atr_value'], \n",
    "                              main_df['future_high_1'], main_df['future_low_1'], main_df['future_high_2'], main_df['future_low_2'], \n",
    "                              main_df['future_high_3'], main_df['future_low_3'], main_df['future_high_4'], main_df['future_low_4'], \n",
    "                              main_df['future_high_5'], main_df['future_low_5']))\n",
    "\n",
    "# Dropping future columns to prevent any look ahead bias\n",
    "for i in [1, 2, 3, 4, 5]:\n",
    "    main_df = main_df.drop(f'future_high_{i}', axis=1)\n",
    "    main_df = main_df.drop(f'future_low_{i}', axis=1)\n",
    "\n",
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177d15ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting list of sorted times to split into train and validation sets\n",
    "times = sorted(main_df.index.values)\n",
    "\n",
    "main_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "main_df.dropna(inplace=True)\n",
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7912d037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the last 20% threshold\n",
    "last_20pct = times[-int(0.20*len(times))]\n",
    "\n",
    "# Splitting into train and validation\n",
    "validation_main_df = main_df[(main_df.index >= last_20pct)]\n",
    "main_df = main_df[(main_df.index < last_20pct)]\n",
    "\n",
    "# Preprocessing, X and y\n",
    "train_x, train_y = preprocess(main_df)\n",
    "validation_x, validation_y = preprocess(validation_main_df)\n",
    "\n",
    "# Checking the outcome of the above\n",
    "print(f'train data: {len(train_x)} validation: {len(validation_x)}')\n",
    "print(f'sells: {train_y.count(0)}, flats: {train_y.count(1)}, buys: {train_y.count(2)}')\n",
    "print(f'VALIDATION sells: {validation_y.count(0)}, flats: {validation_y.count(1)}, buys: {validation_y.count(2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d784c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating arrays for our neural network\n",
    "train_x = np.asarray(train_x)\n",
    "train_y = np.asarray(train_y)\n",
    "validation_x = np.asarray(validation_x)\n",
    "validation_y = np.asarray(validation_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f810e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our LSTM\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(LSTM(16, \n",
    "          kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-5),\n",
    "          bias_regularizer=regularizers.L2(1e-5),\n",
    "          activity_regularizer=regularizers.L2(1e-5),\n",
    "          activation='tanh', input_shape=(train_x.shape[1:]), return_sequences=True)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Bidirectional(LSTM(16, \n",
    "          kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-5),\n",
    "          bias_regularizer=regularizers.L2(1e-5),\n",
    "          activity_regularizer=regularizers.L2(1e-5),\n",
    "          activation='tanh', input_shape=(train_x.shape[1:]))))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6, amsgrad=True)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "\n",
    "filepath = 'NETWORK_NAME_{epoch:02d}'\n",
    "checkpoint = ModelCheckpoint('save_path/{}.model'.format(save_path, filepath, monitor='val_loss', \n",
    "                                                  verbose=1, save_best_only=True, mode='min')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff1eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    validation_data=(validation_x, validation_y),\n",
    "    callbacks=[checkpoint]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
